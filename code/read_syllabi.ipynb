{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose\n",
    "\n",
    "This notebook will provide a walkthrough of how to 1) read a PDF, 2) extract relevant text, 3) identify the key topics, and 4) summarize them all with the chat GPT API.\n",
    "\n",
    "#### The Problem:\n",
    "\n",
    "Imagine you're a student that is prepping to apply to grad school and wants to target a few universities based on the coursework they offer. You know your goals, but you're unsure where to begin. There are *a lot* of syllabi out there, and reading through all of them will require *a lot* of time and effort. You want to make the decision quickly while remaining informed. This is a perfect use-case to process PDFs, summarize the key learnings, and select your courses.\n",
    "\n",
    "#### The Data:\n",
    "\n",
    "In this we are going to use the syllabus from [6500 Statistical Machine Learning](https://stat.osu.edu/courses/stat-6500) taught at The Ohio State University by Dr. Lee. I took this class while studying for my MS Statistics at OSU and really enjoyed the course, so I chose a recent syllabus as our opportunity to extract and summarize text.\n",
    "\n",
    "#### The Example:\n",
    "\n",
    "This code will allow you to use your own OpenAPI key to process the text in a pdf, as well as sort through the content in this syllabus.\n",
    "\n",
    "#### Key Learnings:\n",
    "\n",
    "Along the way I will call out:\n",
    "\n",
    "- Key libraries needed to process PDFs\n",
    "\n",
    "- The components of a call to OpenAPI\n",
    "\n",
    "- Checking your costs upfront (we don't want to go overboard here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## generic libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## beautiful soup to handle the HTML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "## openai libraries\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "## libraries to count tokens etc\n",
    "import tiktoken\n",
    "import textwrap\n",
    "\n",
    "## to help process any outputs\n",
    "import ast\n",
    "import re\n",
    "\n",
    "## load my .env which contains API key and directory\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAPI_KEY\")\n",
    "datapath = os.getenv(\"DATAPATH\")\n",
    "filename = os.getenv(\"FILENAME\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to read in the pdf, this is done using PyMuPDF. We need to pip install this library before we import fitz.\n",
    "\n",
    "```pip install pymupdf```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## the library name is quite different from pymupdf, don't worry about it!\n",
    "import fitz\n",
    "\n",
    "def extract_pdf_text(file_path):\n",
    "    \"\"\"\n",
    "    This function will grab all of the text from the provided path and\n",
    "    return it as a string.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    with fitz.open(file_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAT 6500 Statistical Machine Learning\n",
      "Term: Spring 2024\n",
      "Lectures: MWF 3:00–3:55 PM (3 credit hours) in Cockins Hall 312\n",
      "Instructor: Yoonkyung Lee\n",
      "Oﬃce: 440H Cockins Hall\n",
      "Oﬃce Hours: M 4:00–5:00 PM and F 11:00 AM–12:00 PM or by appointment\n",
      "Email: yklee@stat.osu.edu or lee.2272@osu.edu\n",
      "Grader: Zhizhen Zhao\n",
      "Oﬃce Hours: by appointment only\n",
      "Email: zhao.3053@osu.edu\n",
      "Course Website: https://carmen.osu.edu\n",
      "Course Description:\n",
      "Statistical Machine Learning explores the methodology and algorithms behind modern supervised and\n",
      "unsupervised learning techniques to explore relationships between variables in large, complex datasets.\n",
      "Topics include linear and logistic regression, classiﬁcation, clustering, resampling methods, model selection\n",
      "and regularization, and non-linear regression. Students will also gain exposure to popular statistical ma-\n",
      "chine learning algorithms implemented in R. A focus will be on understanding the formulation of statistical\n",
      "models and their implementation, and the practical\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "pdf_path = datapath + filename\n",
    "pdf_text = extract_pdf_text(pdf_path)\n",
    "print(pdf_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we print the text we see that there is some structure to it - the alarm bells should be going off here. This is typically a sign of HTML. Let's call the first 100 characters and look for HTML formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STAT 6500 Statistical Machine Learning\\nTerm: Spring 2024\\nLectures: MWF 3:00–3:55 PM (3 credit hours)'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's pretty clear that there is html formatting. The \"\\n\" are linebreaks, which provides the formatting we see above. This makes the text pretty, but it also is detrimental to the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why clean HTML before sending to an LLM?\n",
    "\n",
    "1) Costs\n",
    "    - APIs charge for each token and the HTML text increases the token count. Therefore, HTML increases costs\n",
    "\n",
    "2) Quality\n",
    "    - LLMs' \"attention\" will likely ignore the HTML, but it may be meaningful enough to impede the quality of results\n",
    "\n",
    "3) Speed\n",
    "    - More input tokens = longer time to process. Why waste time with something we don't care about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def strip_html(html):\n",
    "\n",
    "    \"\"\"\n",
    "    This function uses BeautifulSoup to remove html from the text string. It may not\n",
    "    be 100% perfect, but it will remove the majority of HTML, which is good enough for\n",
    "    this demo.\n",
    "    \"\"\"\n",
    "\n",
    "    # parse html content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    for data in soup(['style', 'script', 'code', 'a']):\n",
    "        # Remove tags\n",
    "        data.decompose()\n",
    "\n",
    "    text = soup.get_text(separator=\" \", strip=True)\n",
    "    cleaned = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # return data by retrieving the tag content\n",
    "    #return ' '.join(soup.stripped_strings)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## clean the html\n",
    "cleaned_text = strip_html(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STAT 6500 Statistical Machine Learning Term: Spring 2024 Lectures: MWF 3:00–3:55 PM (3 credit hours)'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## call the text to look for any html formatting\n",
    "cleaned_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "Compare the new text to the previous - it's pretty clear the html is gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAT 6500 Statistical Machine Learning Term: Spring 2024 Lectures: MWF 3:00–3:55 PM (3 credit hours)\n",
      "\n",
      "\n",
      "STAT 6500 Statistical Machine Learning\n",
      "Term: Spring 2024\n",
      "Lectures: MWF 3:00–3:55 PM (3 credit hours)\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_text[:100])\n",
    "print(\"\\n\")\n",
    "print(pdf_text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving on to the API Call\n",
    "\n",
    "Getting ready to call the API takes some prep. We need to complete a couple of prep steps:\n",
    "\n",
    "1) Pick a model\n",
    "\n",
    "2) Count the number of tokens - if the text is too long, we will run into a variety of issues\n",
    "\n",
    "3) Engineer a prompt (seriously easier than it sounds)\n",
    "    - Set the context\n",
    "    - Give the command with the prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection\n",
    "\n",
    "I am going to use gpt-3.5-turbo-0125 because it does a great job extracting topics and sumamrizing text while being a cheaper option. As of 5/11/2025 the 4.0+ models are out, but they are more expensive. If this was a business use case or a more complex task, I would choose a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model = \"gpt-3.5-turbo-0125\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the tokens\n",
    "\n",
    "The script below needs the model and text, which are ready to go, and will tell us the tokens before sending to the API. This is generally wise - sometimes it's better to chunk the text and summarize the outputs in another step. Syllabi are long, so this is a very real possibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def count_tokens(text, model):\n",
    "    '''\n",
    "    Counts the number of tokens for the provided model. Can be used to kill an api call,\n",
    "    estimate costs, chunk, etc. depending on the length of the input.\n",
    "\n",
    "    Parameters:\n",
    "                - text (str): this is the text before it is converted to tokens\n",
    "                - model (str): this specifies the openai model chosen\n",
    "    Returns:\n",
    "                - len(tokens) (int): the number of tokens\n",
    "    '''\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(cleaned_text, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2069 tokens is nothing. This will costs fractions of a cent and be incredibly cheap. We're almost ready to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineer the prompts\n",
    "\n",
    "1) We want to include a system message, which provides context for the LLM. This helps guide the LLM to perform our task with more precision. I always use these and highly recommend them. Be precise and creative. Imagine an expert performing the task - how would you describe them? What would you want them to emphasize during the task?\n",
    "    - Imagine this expert is really good at their job, but terrible at assuming context. Giving them specific instructions will help them do a better job.\n",
    "\n",
    "2) The prompt should provide a little bit more context, but also specify the output. I want a bulleted list of topics that contain no more than 3-5 words per bullet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\n",
    "        \"\"\" You are an expert education analyst. Your job is to read a course syllabus and extract the key learning topics\n",
    "            a student can expect to study. Focus on concepts, skill, machine learning algorithms, or other statistics topics\n",
    "            that the course aims to teach Masters-level statistics students.\n",
    "            Ignore administrative details such as grading policies, attendance, or instructor bios.\n",
    "            Present the output as a concise list of the main subject areas or skills covered in the course.\"\"\"\n",
    "    )\n",
    "}\n",
    "\n",
    "prompt = \"\"\"Here is the syllabus for a university-level course. Please extract the main learning topics and skills a student will gain\n",
    "            from this course, return them in a bulleted list where each bullet is no more than 3-5 wordsin length. The text is as follows: {}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally we make the call\n",
    "\n",
    "First we write a function to handle this, then we send it off to the API, clean the response, and look at the results.\n",
    "\n",
    "Parameters:\n",
    " - Temperature: This controls the randomness of the results. Generally, the extremes are bad. 1.0 is no randomness and close to 0.0 is nearly completely random. We want something in the middle, but guided. I generally like 0.7, but this is also something I'd tune to get the performance I want.\n",
    "\n",
    " - Penalty: In this case it's a frequency penalty. We don't want to see the same bullets repeatedly, so we will penalize the model for repeating itself. More penalty = less repetition. I don't always use this parameter, but I think it fits this problem nicely. We'll do 0.2. The default is 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def extract_bulleted_topics(systemPrep, prompt, model, temp, penalty):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            systemPrep,\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temp,\n",
    "        frequency_penalty = penalty,\n",
    "        max_tokens = 800\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "### use the API Key\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "bullets = extract_bulleted_topics(system_message, prompt.format(cleaned_text), model, 0.7, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Statistical Machine Learning Methodology\n",
      "- Supervised and Unsupervised Learning Techniques\n",
      "- Linear and Logistic Regression\n",
      "- Classification and Clustering\n",
      "- Resampling Methods\n",
      "- Model Selection and Regularization\n",
      "- Non-linear Regression\n",
      "- Statistical Learning Framework\n",
      "- Statistical Models Formulation and Evaluation\n",
      "- Learning Algorithms Rationale and Implementation\n",
      "- Quantitative Evaluation of Learning Methods\n",
      "- Application of Learning Methods to Real-world Data\n"
     ]
    }
   ],
   "source": [
    "print(bullets.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "I think the model did a great job hitting the highlights of the course. I would say that I learned all of that while in grad school, and I think a student would benefit from this list. Additionally, I think this is generalizable to any statistics course. For other disciplines, the context and prompt may need to be tweaked, but this is 95% of the way to completion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
